{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import StochasticPolicy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from make_data import BoxMaker\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = StochasticPolicy(80*45,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamaker = BoxMaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=datamaker.get_data_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = []\n",
    "dim = []\n",
    "action = []\n",
    "for i in range(len(data)):\n",
    "    state.append(data[i,0])\n",
    "    dim.append(data[i,1])\n",
    "    action.append(data[i,2][:2])\n",
    "state=torch.from_numpy(np.array(state))/45\n",
    "dim=torch.from_numpy(np.array(dim))/45\n",
    "action=torch.from_numpy(np.array(action))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,m,s=policy.sample(state.float(),dim.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7975,  0.8363],\n",
       "        [ 0.7626,  0.6619],\n",
       "        [-0.7027, -0.6847],\n",
       "        [ 0.5062,  0.6905],\n",
       "        [-0.4756,  0.1252],\n",
       "        [ 0.5738, -0.3649],\n",
       "        [-0.7550, -0.0152],\n",
       "        [-0.9898, -0.9477],\n",
       "        [ 0.5108, -0.4468],\n",
       "        [ 0.9623,  0.5362],\n",
       "        [-0.4386, -0.5187],\n",
       "        [ 0.7979,  0.0224],\n",
       "        [ 0.5941, -0.3949],\n",
       "        [-0.9985, -0.5595],\n",
       "        [ 0.9583, -0.5775],\n",
       "        [-0.2425, -0.4407],\n",
       "        [-0.9505,  0.0014],\n",
       "        [-0.4073, -0.2848],\n",
       "        [-0.9988, -0.2925],\n",
       "        [ 0.4370,  0.1461],\n",
       "        [-0.9996,  0.4023],\n",
       "        [-0.9999,  0.0979],\n",
       "        [-0.8732, -0.0867],\n",
       "        [ 1.0000, -0.2277],\n",
       "        [ 0.9999,  0.5163],\n",
       "        [ 0.9963,  0.3143],\n",
       "        [-0.8990, -0.2464]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shifted_action(action):\n",
    "#     action = action.detach().numpy()\n",
    "    x = action[:,0]\n",
    "    y = action[:,1]\n",
    "    x = x*40 + 40\n",
    "    y = y*45/2 + 45/2\n",
    "#     return x.astype(int),y.astype(int)\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=get_shifted_action(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=torch.cat([x.unsqueeze(1),y.unsqueeze(1)],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1198.8383, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.mse_loss(pred,action.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Imitation Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model import StochasticPolicy\n",
    "from make_data import BoxMaker\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StochasticPolicy(\n",
       "  (linear1): Linear(in_features=3600, out_features=500, bias=True)\n",
       "  (linear2): Linear(in_features=500, out_features=100, bias=True)\n",
       "  (linear3_mean): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (linear4_mean): Linear(in_features=50, out_features=9, bias=True)\n",
       "  (linear5_mean): Linear(in_features=12, out_features=2, bias=True)\n",
       "  (linear3_std): Linear(in_features=100, out_features=50, bias=True)\n",
       "  (linear4_std): Linear(in_features=50, out_features=9, bias=True)\n",
       "  (linear5_std): Linear(in_features=12, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy = StochasticPolicy(80*45,2)\n",
    "checkpoint = torch.load('./Models/policy.pt')\n",
    "policy.load_state_dict(checkpoint['model_state_dict'])\n",
    "policy.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_maker=BoxMaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_maker.get_data_dict()\n",
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shifted_action(action):\n",
    "#     action = action.detach().numpy()\n",
    "    x = action[:,0]\n",
    "    y = action[:,1]\n",
    "    y = y*40 + 40\n",
    "    x = x*45/2 + 45/2\n",
    "#     return x.astype(int),y.astype(int)\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeasibility(ldc,x,y,l,b,h):\n",
    "    feasible = 0\n",
    "    if len(np.unique(ldc[x:x+b,y:y+l])) == 1 and ldc[x,y]+h<=45:\n",
    "        feasible=1\n",
    "    return feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_maker.get_data_dict()\n",
    "data=np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 25 21 15 [0 0 0]\n",
      "PLACE\n",
      "[6, 7] 16 21 15 [ 0 25  0]\n",
      "[6, 7] 13 21 15 [ 0 41  0]\n",
      "[6, 7] 13 21 15 [ 0 54  0]\n",
      "[6, 7] 13 21 15 [ 0 67  0]\n",
      "[6, 7] 25 14 15 [21  0  0]\n",
      "[6, 7] 16 14 15 [21 25  0]\n",
      "PLACE\n",
      "[2, 8] 13 14 15 [21 41  0]\n",
      "[2, 8] 13 14 15 [21 54  0]\n",
      "[2, 8] 13 14 15 [21 67  0]\n",
      "[2, 8] 25 10 15 [35  0  0]\n",
      "[2, 8] 16 10 15 [35 25  0]\n",
      "[2, 8] 13 10 15 [35 41  0]\n",
      "[2, 8] 13 10 15 [35 54  0]\n",
      "[2, 8] 13 10 15 [35 67  0]\n",
      "[2, 8] 25 21 17 [ 0  0 15]\n",
      "[2, 8] 16 21 17 [ 0 25 15]\n",
      "[2, 8] 13 21 17 [ 0 41 15]\n",
      "[2, 8] 13 21 17 [ 0 54 15]\n",
      "[2, 8] 13 21 17 [ 0 67 15]\n",
      "[2, 8] 25 14 17 [21  0 15]\n",
      "[2, 8] 16 14 17 [21 25 15]\n",
      "[2, 8] 13 14 17 [21 41 15]\n",
      "[2, 8] 13 14 17 [21 54 15]\n",
      "[2, 8] 13 14 17 [21 67 15]\n",
      "[2, 8] 25 10 17 [35  0 15]\n",
      "[2, 8] 16 10 17 [35 25 15]\n",
      "[2, 8] 13 10 17 [35 41 15]\n",
      "[2, 8] 13 10 17 [35 54 15]\n",
      "[2, 8] 13 10 17 [35 67 15]\n",
      "[2, 8] 25 21 13 [ 0  0 32]\n",
      "[2, 8] 16 21 13 [ 0 25 32]\n",
      "[2, 8] 13 21 13 [ 0 41 32]\n",
      "[2, 8] 13 21 13 [ 0 54 32]\n",
      "[2, 8] 13 21 13 [ 0 67 32]\n",
      "[2, 8] 25 14 13 [21  0 32]\n",
      "[2, 8] 16 14 13 [21 25 32]\n",
      "[2, 8] 13 14 13 [21 41 32]\n",
      "[2, 8] 13 14 13 [21 54 32]\n",
      "[2, 8] 13 14 13 [21 67 32]\n",
      "[2, 8] 25 10 13 [35  0 32]\n",
      "[2, 8] 16 10 13 [35 25 32]\n",
      "[2, 8] 13 10 13 [35 41 32]\n",
      "[2, 8] 13 10 13 [35 54 32]\n",
      "[2, 8] 13 10 13 [35 67 32]\n",
      "6.935185185185184\n"
     ]
    }
   ],
   "source": [
    "data = data_maker.get_data_dict()\n",
    "data=np.array(data)\n",
    "ldc=np.zeros((45,80))\n",
    "act = 5\n",
    "k=3\n",
    "vol=0\n",
    "search = np.arange(0,k,1)-int(k/2)\n",
    "state = data[0,0]\n",
    "while len(data)>0:\n",
    "    num_act=0\n",
    "    state = np.copy(ldc.flatten())\n",
    "    dim = data[0,1]\n",
    "    ideal_pos=data[0,2]\n",
    "    state_feed = torch.from_numpy(np.array(state))/45\n",
    "    dim_feed   = torch.from_numpy(np.array(dim))/45\n",
    "    a,m,s=policy.sample(state_feed.unsqueeze(0).float(),dim_feed.unsqueeze(0).float())\n",
    "    x,y=get_shifted_action(a)\n",
    "    x = x.int().detach() \n",
    "    y = y.int().detach()\n",
    "    l=dim[0]\n",
    "    b=dim[1]\n",
    "    h=dim[2]\n",
    "    feasible = getFeasibility(ldc,x,y,l,b,h)\n",
    "    print([x.numpy()[0],y.numpy()[0]],l,b,h,ideal_pos)\n",
    "    if feasible:\n",
    "        ldc[x:x+b,y:y+l] += h\n",
    "        print('PLACE')\n",
    "        vol += l*b*h\n",
    "        data = np.delete(data,0,0)\n",
    "        act = 1\n",
    "    done=0\n",
    "    if not feasible:\n",
    "        act = 0\n",
    "        # check neighbouring region\n",
    "        for i in search:\n",
    "            for j in search:\n",
    "                x_test = np.maximum(0,x+i)\n",
    "                y_test = np.maximum(0,y+j)\n",
    "                x_test = np.minimum(x_test,45)\n",
    "                y_test = np.minimum(y_test,80)\n",
    "                feasible = getFeasibility(ldc,x_test,y_test,l,b,h)\n",
    "#                 print(x_test,y_test)\n",
    "                if feasible:\n",
    "                    ldc[x_test:x_test+b,y_test:y_test+l] += h\n",
    "                    vol+=l+b+h\n",
    "                    print('PLACE')\n",
    "                    data = np.delete(data,0,0)\n",
    "                    act=1\n",
    "                    done=1\n",
    "                    break\n",
    "            if done:\n",
    "                break\n",
    "        data = np.delete(data,0,0)\n",
    "                \n",
    "                \n",
    "#     plt.imshow(ldc,cmap='hot',vmin=0,vmax=45)\n",
    "#     plt.show()\n",
    "print(vol/(45*45*80)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy = np.copy(data)\n",
    "data_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.delete(data_copy,0,0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from make_data import BoxMaker\n",
    "from model import StochasticPolicyCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.rand((1,4,45,80))\n",
    "b = torch.rand((1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy=StochasticPolicyCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.3243, -0.1640]], grad_fn=<TanhBackward>),\n",
       " tensor([[-1.9542]], grad_fn=<SumBackward2>),\n",
       " tensor([[ 0.4402, -0.3998]], grad_fn=<TanhBackward>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy.sample(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_maker = BoxMaker(45,45,80)\n",
    "data = data_maker.get_data_dict(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.zeros((4,45,80))\n",
    "dim   = np.zeros((12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "replayBuffer=[]\n",
    "for i in range(5):\n",
    "    state = np.roll(state,axis=0,shift=1)\n",
    "    state[0,:,:] = data[i][0]\n",
    "#     states.append(state)\n",
    "    dim = np.roll(dim,shift=3)\n",
    "    dim[:3] = data[i][1]\n",
    "#     dims.append(dim)\n",
    "    action = data[i][2]\n",
    "    replayBuffer.append([state,dim,action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]]),\n",
       "       array([39., 22., 19.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]),\n",
       "       array([0, 0, 0])], dtype=object)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(replayBuffer)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "\tdef __init__(self, max_size=1e4):\n",
    "\t\tself.storage = []\n",
    "\t\tself.max_size = max_size\n",
    "\t\tself.ptr = 0\n",
    "\n",
    "\tdef add(self, data):\n",
    "\t\tif len(self.storage) == self.max_size:\n",
    "\t\t\tself.storage[int(self.ptr)] = data\n",
    "\t\t\tself.ptr = (self.ptr + 1) % self.max_size\n",
    "\t\telse:\n",
    "\t\t\tself.storage.append(data)\n",
    "\n",
    "\tdef sample(self, batch_size=1):\n",
    "\t\tind = np.random.randint(0, len(self.storage), size=batch_size)\n",
    "\t\t#[st_img,dim,action]\n",
    "\t\tx, y, u = [], [], []\n",
    "\t\tfor i in ind:\n",
    "\t\t\tX, Y, U = self.storage[i]\n",
    "\t\t\tx.append(np.array(X, copy=False))\n",
    "\t\t\ty.append(np.array(Y, copy=False))\n",
    "\t\t\tu.append(np.array(U, copy=False))\n",
    "\n",
    "\t\treturn np.array(x), np.array(y), np.array(u)\n",
    "buff = ReplayBuffer(3)\n",
    "for i in range(5):\n",
    "    state = np.roll(state,axis=0,shift=1)\n",
    "    state[0,:,:] = data[i][0]\n",
    "#     states.append(state)\n",
    "    dim = np.roll(dim,shift=3)\n",
    "    dim[:3] = data[i][1]\n",
    "#     dims.append(dim)\n",
    "    action = data[i][2][:2]\n",
    "    buff.add([state,dim,action])\n",
    "#     replayBuffer.append([state,dim,action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 45, 80) (2, 12) (2, 2)\n"
     ]
    }
   ],
   "source": [
    "x,y,u = buff.sample(2)\n",
    "print(x.shape,y.shape,u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_state = data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[3][:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "state[:,:,0] = cur_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 80, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.roll(state,axis=2,shift=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Imitation Learning with history of states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import StochasticPolicyCNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from make_data import BoxMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shifted_action(action):\n",
    "#     action = action.detach().numpy()\n",
    "    x = action[:,0]\n",
    "    y = action[:,1]\n",
    "    y = y*40 + 40\n",
    "    x = x*45/2 + 45/2\n",
    "#     return x.astype(int),y.astype(int)\n",
    "    return x,y\n",
    "\n",
    "def getFeasibility(ldc,x,y,l,b,h):\n",
    "    feasible = 0\n",
    "    if len(np.unique(ldc[x:x+b,y:y+l])) == 1 and ldc[x,y]+h<=45:\n",
    "        feasible=1\n",
    "    return feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.zeros((4,45,80))\n",
    "dim   = np.zeros((12))\n",
    "ldc = np.zeros((45,80))\n",
    "data_maker = BoxMaker(45,45,80)\n",
    "data = data_maker.get_data_dict(False)\n",
    "def show(a):\n",
    "    plt.imshow(a,cmap='hot',vmin=0,vmax=45)\n",
    "    plt.show()\n",
    "states=[]\n",
    "dims=[]\n",
    "actions=[]\n",
    "for i in range(len(data)):\n",
    "    ldc = np.copy(data[i][0])\n",
    "    state = np.roll(state,axis=0,shift=1)\n",
    "    state[0,:,:] = data[i][0]\n",
    "    states.append(state)\n",
    "    dim = np.roll(dim,shift=3)\n",
    "    dim[:3] = data[i][1]\n",
    "    dims.append(dim)\n",
    "    action = data[i][2][:2]\n",
    "    actions.append(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "policy = StochasticPolicyCNN()\n",
    "checkpoint = torch.load('./Models/policy.pt')\n",
    "policy.load_state_dict(checkpoint['model_state_dict'])\n",
    "policy.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] [0 0]\n",
      "[4, 12] [0 0]\n",
      "[0, 0] [0 0]\n",
      "[17, 16] [23  0]\n",
      "[21, 0] [23  0]\n",
      "[20, 0] [23  0]\n",
      "[31, 0] [33  0]\n",
      "[31, 0] [33  0]\n",
      "[31, 0] [33  0]\n",
      "[0, 38] [ 0 34]\n",
      "[0, 36] [ 0 34]\n",
      "[0, 32] [ 0 34]\n",
      "[23, 33] [23 34]\n",
      "[23, 34] [23 34]\n",
      "[23, 33] [23 34]\n",
      "[32, 33] [33 34]\n",
      "[33, 32] [33 34]\n",
      "[32, 32] [33 34]\n",
      "[0, 49] [ 0 48]\n",
      "[0, 47] [ 0 48]\n",
      "[0, 47] [ 0 48]\n",
      "[24, 46] [23 48]\n",
      "[23, 48] [23 48]\n",
      "[23, 47] [23 48]\n",
      "[32, 46] [33 48]\n",
      "[32, 47] [33 48]\n",
      "[32, 47] [33 48]\n",
      "[0, 62] [ 0 62]\n",
      "[0, 62] [ 0 62]\n",
      "[0, 62] [ 0 62]\n",
      "[23, 62] [23 62]\n",
      "[22, 61] [23 62]\n",
      "[22, 60] [23 62]\n",
      "[33, 61] [33 62]\n",
      "[33, 61] [33 62]\n",
      "[33, 61] [33 62]\n"
     ]
    }
   ],
   "source": [
    "state = np.zeros((4,45,80))\n",
    "dim   = np.zeros((12))\n",
    "ldc = np.zeros((45,80))\n",
    "data_maker = BoxMaker(45,45,80)\n",
    "data = data_maker.get_data_dict(False)\n",
    "def show(a):\n",
    "    plt.imshow(a,cmap='hot',vmin=0,vmax=45)\n",
    "    plt.show()\n",
    "states=[]\n",
    "dims=[]\n",
    "actions=[]\n",
    "for i in range(len(data)):\n",
    "    ldc = np.copy(data[i][0])\n",
    "    state = np.roll(state,axis=0,shift=1)\n",
    "    state[0,:,:] = data[i][0]\n",
    "    states.append(state)\n",
    "    dim = np.roll(dim,shift=3)\n",
    "    dim[:3] = data[i][1]\n",
    "    dims.append(dim)\n",
    "    action = data[i][2][:2]\n",
    "    actions.append(action)\n",
    "opt=[]\n",
    "pred=[]\n",
    "for i in range(len(states)):\n",
    "    feed_state = torch.FloatTensor(states[i]/45).unsqueeze(0)\n",
    "    feed_dim   = torch.FloatTensor(dims[i]/45).unsqueeze(0)\n",
    "    a,m,s = policy.sample(feed_state,feed_dim)\n",
    "    x = get_shifted_action(a)[0].detach().numpy()[0]\n",
    "    y = get_shifted_action(a)[1].detach().numpy()[0]\n",
    "    pred.append([int(x),int(y)])\n",
    "#     opt.append(actions[i])\n",
    "    print(str([int(x),int(y)]),str(actions[i]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_df = pd.DataFrame(opt)\n",
    "opt_df = opt_df.rename(columns={0:'opt_x',1:'opt_y'})\n",
    "pred_df= pd.DataFrame(pred)\n",
    "pred_df = pred_df.rename(columns={0:'pred_x',1:'pred_y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pred_df,opt_df],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test IL with history with actual change in state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from model import StochasticPolicyCNN\n",
    "import torch\n",
    "from make_data import BoxMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shifted_action(action):\n",
    "#     action = action.detach().numpy()\n",
    "    x = action[:,0]\n",
    "    y = action[:,1]\n",
    "    y = y*40 + 40\n",
    "    x = x*45/2 + 45/2\n",
    "#     return x.astype(int),y.astype(int)\n",
    "    return x,y\n",
    "def getFeasibility(ldc,x,y,l,b,h):\n",
    "    feasible = 0\n",
    "    if len(np.unique(ldc[x:x+b,y:y+l])) == 1 and ldc[x,y]+h<=45:\n",
    "        feasible=1\n",
    "    return feasible"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
